{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4898c49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing training data...\n",
      "Processed 2901/2929 images.\n",
      "Processed 2401/2929 images.\n",
      "Processed 3401/2929 images.\n",
      "Processed 3201/2929 images.\n",
      "Processed 901/2929 images.\n",
      "Processed 101/2929 images.\n",
      "Processed 3101/2929 images.\n",
      "Processed 1601/2929 images.\n",
      "Processed 1101/2929 images.\n",
      "Processed 1001/2929 images.\n",
      "Processed 3001/2929 images.\n",
      "Processed 301/2929 images.\n",
      "Processed 2501/2929 images.\n",
      "Processed 801/2929 images.\n",
      "Processed 501/2929 images.\n",
      "Processed 2701/2929 images.\n",
      "Processed 3301/2929 images.\n",
      "Processed 3501/2929 images.\n",
      "Processed 2801/2929 images.\n",
      "Processed 1701/2929 images.\n",
      "Processed 1901/2929 images.\n",
      "Processed 3601/2929 images.\n",
      "Processed 2101/2929 images.\n",
      "Processed 2001/2929 images.\n",
      "Processed 1301/2929 images.\n",
      "Processed 2201/2929 images.\n",
      "Processed 401/2929 images.\n",
      "Processed 1401/2929 images.\n",
      "Processed 201/2929 images.\n",
      "Processed 1501/2929 images.\n",
      "Processed 601/2929 images.\n",
      "Processed 2301/2929 images.\n",
      "Preprocessing test data...\n",
      "Processed 2601/733 images.\n",
      "Processed 1801/733 images.\n",
      "Processed 701/733 images.\n",
      "Processed 1/733 images.\n",
      "Processed 1201/733 images.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, BatchNormalization, Dropout, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Constants\n",
    "IMG_DIM = 224\n",
    "CHANNEL_SIZE = 3\n",
    "NUM_CLASSES = 5\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "SEED = 42\n",
    "\n",
    "# Path to data\n",
    "data_dir = '/home/gcekcse/Documents/ML_Project_hk/aptos2019-blindness-detection/G1/G1_images'\n",
    "labels_file = '/home/gcekcse/Documents/ML_Project_hk/aptos2019-blindness-detection/G1/G1.csv'\n",
    "\n",
    "# Load labels\n",
    "df = pd.read_csv(labels_file)\n",
    "\n",
    "# Split data into training and test sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=SEED)\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Error loading {image_path}\")\n",
    "        return None\n",
    "    img = cv2.resize(img, (IMG_DIM, IMG_DIM))\n",
    "    img = img / 255.0  # Normalize\n",
    "    return img\n",
    "\n",
    "def preprocess_data(dataframe, data_dir):\n",
    "    X = []\n",
    "    y = []\n",
    "    for idx, row in dataframe.iterrows():\n",
    "        img_path = os.path.join(data_dir, row['id_code'] + \".png\")\n",
    "        img = preprocess_image(img_path)\n",
    "        if img is not None:\n",
    "            X.append(img)\n",
    "            y.append(row['diagnosis'])\n",
    "        if idx % 100 == 0:\n",
    "            print(f\"Processed {idx + 1}/{len(dataframe)} images.\")\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Preprocess training and test data\n",
    "print(\"Preprocessing training data...\")\n",
    "X_train, y_train = preprocess_data(train_df, data_dir)\n",
    "print(\"Preprocessing test data...\")\n",
    "X_test, y_test = preprocess_data(test_df, data_dir)\n",
    "\n",
    "# Create data augmentation generator\n",
    "datagen = ImageDataGenerator(rotation_range=20, zoom_range=0.15, width_shift_range=0.2,\n",
    "                             height_shift_range=0.2, shear_range=0.15, horizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e80c0821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ResNet50 model\n",
    "def create_resnet(img_dim, CHANNEL, n_class):\n",
    "    input_tensor = Input(shape=(img_dim, img_dim, CHANNEL))\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(2048, activation='elu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(1024, activation='elu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='elu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output_layer = Dense(n_class, activation='softmax')(x)\n",
    "\n",
    "    model_resnet = Model(input_tensor, output_layer)\n",
    "    return model_resnet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fc8714c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-30 15:18:44.126178: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-30 15:18:44.231747: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-30 15:18:44.234698: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.2/lib64\n",
      "2024-09-30 15:18:44.234716: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gcekcse/.local/lib/python3.10/site-packages/tensorboard/compat/__init__.py\", line 42, in tf\n",
      "    from tensorboard.compat import notf  # noqa: F401\n",
      "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/home/gcekcse/.local/lib/python3.10/site-packages/tensorboard/compat/__init__.py)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gcekcse/.local/bin/tensorboard\", line 8, in <module>\n",
      "    sys.exit(run_main())\n",
      "  File \"/home/gcekcse/.local/lib/python3.10/site-packages/tensorboard/main.py\", line 38, in run_main\n",
      "    main_lib.global_init()\n",
      "  File \"/home/gcekcse/.local/lib/python3.10/site-packages/tensorboard/main_lib.py\", line 50, in global_init\n",
      "    if getattr(tf, \"__version__\", \"stub\") == \"stub\":\n",
      "  File \"/home/gcekcse/.local/lib/python3.10/site-packages/tensorboard/lazy.py\", line 65, in __getattr__\n",
      "    return getattr(load_once(self), attr_name)\n",
      "  File \"/home/gcekcse/.local/lib/python3.10/site-packages/tensorboard/lazy.py\", line 97, in wrapper\n",
      "    cache[arg] = f(arg)\n",
      "  File \"/home/gcekcse/.local/lib/python3.10/site-packages/tensorboard/lazy.py\", line 50, in load_once\n",
      "    module = load_fn()\n",
      "  File \"/home/gcekcse/.local/lib/python3.10/site-packages/tensorboard/compat/__init__.py\", line 45, in tf\n",
      "    import tensorflow\n",
      "  File \"/home/gcekcse/.local/lib/python3.10/site-packages/tensorflow/__init__.py\", line 37, in <module>\n",
      "    from tensorflow.python.tools import module_util as _module_util\n",
      "  File \"/home/gcekcse/.local/lib/python3.10/site-packages/tensorflow/python/__init__.py\", line 37, in <module>\n",
      "    from tensorflow.python.eager import context\n",
      "  File \"/home/gcekcse/.local/lib/python3.10/site-packages/tensorflow/python/eager/context.py\", line 28, in <module>\n",
      "    from tensorflow.core.framework import function_pb2\n",
      "  File \"/home/gcekcse/.local/lib/python3.10/site-packages/tensorflow/core/framework/function_pb2.py\", line 16, in <module>\n",
      "    from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2\n",
      "  File \"/home/gcekcse/.local/lib/python3.10/site-packages/tensorflow/core/framework/attr_value_pb2.py\", line 16, in <module>\n",
      "    from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2\n",
      "  File \"/home/gcekcse/.local/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py\", line 16, in <module>\n",
      "    from tensorflow.core.framework import resource_handle_pb2 as tensorflow_dot_core_dot_framework_dot_resource__handle__pb2\n",
      "  File \"/home/gcekcse/.local/lib/python3.10/site-packages/tensorflow/core/framework/resource_handle_pb2.py\", line 16, in <module>\n",
      "    from tensorflow.core.framework import tensor_shape_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\n",
      "  File \"/home/gcekcse/.local/lib/python3.10/site-packages/tensorflow/core/framework/tensor_shape_pb2.py\", line 36, in <module>\n",
      "    _descriptor.FieldDescriptor(\n",
      "  File \"/home/gcekcse/.local/lib/python3.10/site-packages/google/protobuf/descriptor.py\", line 561, in __new__\n",
      "    _message.Message._CheckCalledFromGeneratedFile()\n",
      "TypeError: Descriptors cannot not be created directly.\n",
      "If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\n",
      "If you cannot immediately regenerate your protos, some other possible workarounds are:\n",
      " 1. Downgrade the protobuf package to 3.20.x or lower.\n",
      " 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n",
      "\n",
      "More information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37c06bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-30 15:23:46.348692: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The filepath provided must end in `.keras` (Keras model format). Received: filepath=model_checkpoint_epoch_{epoch:02d}.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m model_resnet\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Define ModelCheckpoint callback to save the model for each epoch\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m checkpoint_callback \u001b[38;5;241m=\u001b[39m \u001b[43mModelCheckpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_checkpoint_epoch_\u001b[39;49m\u001b[38;5;132;43;01m{epoch:02d}\u001b[39;49;00m\u001b[38;5;124;43m.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Save model as 'model_checkpoint_epoch_xx.h5'\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Save at the end of each epoch\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_best_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Set to True to only save the best model based on `monitor`\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_weights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Save the full model (architecture + weights)\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Print message after each save\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Define TensorBoard callback to log metrics\u001b[39;00m\n\u001b[1;32m     18\u001b[0m log_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogs/fit/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/hkenv/lib/python3.12/site-packages/keras/src/callbacks/model_checkpoint.py:191\u001b[0m, in \u001b[0;36mModelCheckpoint.__init__\u001b[0;34m(self, filepath, monitor, verbose, save_best_only, save_weights_only, mode, save_freq, initial_value_threshold)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 191\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    192\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe filepath provided must end in `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    193\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(Keras model format). Received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    194\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    195\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: The filepath provided must end in `.keras` (Keras model format). Received: filepath=model_checkpoint_epoch_{epoch:02d}.h5"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "import datetime\n",
    "\n",
    "# Create and compile the model\n",
    "model_resnet = create_resnet(IMG_DIM, CHANNEL_SIZE, NUM_CLASSES)\n",
    "model_resnet.compile(optimizer=Adam(learning_rate=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define ModelCheckpoint callback to save the model for each epoch\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='model_checkpoint_epoch_{epoch:02d}.h5',  # Save model as 'model_checkpoint_epoch_xx.h5'\n",
    "    save_freq='epoch',  # Save at the end of each epoch\n",
    "    save_best_only=False,  # Set to True to only save the best model based on `monitor`\n",
    "    save_weights_only=False,  # Save the full model (architecture + weights)\n",
    "    verbose=1  # Print message after each save\n",
    ")\n",
    "\n",
    "# Define TensorBoard callback to log metrics\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(\n",
    "    log_dir=log_dir,  # Specify the log directory\n",
    "    histogram_freq=1,  # Record activation histograms every epoch\n",
    "    write_graph=True,  # Visualize the graph\n",
    "    write_images=True  # Log model weights as images\n",
    ")\n",
    "\n",
    "# Train the model with both ModelCheckpoint and TensorBoard callbacks\n",
    "history = model_resnet.fit(\n",
    "    datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[checkpoint_callback, tensorboard_callback]  # Add both callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f02e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate the model\n",
    "(eval_loss, eval_accuracy) = model_resnet.evaluate(X_test, y_test)\n",
    "print(f\"Accuracy: {eval_accuracy * 100:.2f}%\")\n",
    "print(f\"Loss: {eval_loss}\")\n",
    "\n",
    "# Classification report\n",
    "y_pred = np.argmax(model_resnet.predict(X_test), axis=1)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ROC-AUC score\n",
    "y_pred_prob = model_resnet.predict(X_test)\n",
    "print(f\"AUC-ROC: {roc_auc_score(y_test, y_pred_prob, multi_class='ovo')}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (hkenv)",
   "language": "python",
   "name": "hkenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
